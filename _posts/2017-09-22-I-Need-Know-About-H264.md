---
layout: post
title: 我需要知道：H.264
tags:
    - 基础知识
    - 流媒体
---

我在今年年初离开 YOLO 加入了一家在流媒体领域具有极深积累的小公司，负责视频群聊 SDK 的开发工作，YOLO 是一款直播 APP，我常戏称这是从技术下游（SDK 使用方）跑到了技术上游（SDK 提供方）。不过事情当然不是这么简单，经过长期的思考和探讨，我最终确认：实时多媒体领域，更宽泛一点来讲，实时视觉、感知的展现，在未来极长一段时间内都存在很大的需求，也存在很大的挑战，所以这将是我长期技术积累的大方向。

明确了大方向之后，就需要不懈地积累了。我一直强调基础知识的重要性，最近我就花时间学习了 H.264 的基础（[《新一代视频压缩编码标准:H.264/AVC(第2版)》](https://www.amazon.cn/%E6%96%B0%E4%B8%80%E4%BB%A3%E8%A7%86%E9%A2%91%E5%8E%8B%E7%BC%A9%E7%BC%96%E7%A0%81%E6%A0%87%E5%87%86-H-264-AVC-%E6%AF%95%E5%8E%9A%E6%9D%B0/dp/B008QM2EG2/ref=sr_1_1?s=books&ie=UTF8&qid=1505913595&sr=1-1&keywords=h264)），力求搞清楚两个问题：**H.264 编解码的过程是怎样的？H.264 码流的结构是怎样的？**

_以前看书后分享的只是零碎的笔记，没敢发布博客，这一篇我力求根据自己的理解，把上述两个核心问题描述清楚，细节内容篇幅有限，还是需要阅读原书的，当然，最正宗的资料莫过于 [H.264 SPEC](https://www.itu.int/rec/T-REC-H.264) 了。_

## 视频编解码基础

### 视频为什么需要编码？

**因为原始视频数据量太大！**

以分辨率为 640x480，帧率为 30 fps 的视频为例，如果直接传输/存储原始 RGBA 数据，那码率将高达 281.25 Mbps（在专业领域码率单位通常使用 bit 而非 byte），1280x720 30 fps 码率更将高达 843.75 Mbps。

+ `640*480*4*8*30 = 281.25 Mbps`
+ `1280*720*4*8*30 = 843.75 Mbps`

这么高的码率显然不能直接使用。即便换成更节省空间的 YUV 格式，无论是通过网络传输还是磁盘存储，码率依然高得不可接受，所以必须进行编码压缩。

### 视频为什么可以编码？

**因为视频数据存在冗余。**

首先是数据冗余，图像的各个像素之间、视频的各帧之间存在着很强的相关性。比如图片中的一堵白色墙面，各个区域的像素值很接近，比如日常拍摄的视频，内容基本上都是相同的物体在不同的位置移动。

其次是视觉冗余，根据人眼的一些特性比如亮度辨别阈值、视觉阈值、对亮度和色度的敏感度不同，即便引入适量的误差，也不会被察觉出来。

### 视频编码有哪些主要技术？

视频编码的目标就是在尽可能压缩数据的同时，保证视频的质量。因此，视频编码的主要技术都是围绕消除冗余、提高压缩比的。当然，考虑到基于分组交换的网络环境，以及实时多媒体应用场景，视频编码也要考虑网络自适应、容错等问题。

**预测编码与运动补偿**：预测编码旨在消除视频的数据冗余，经过编码压缩后传输的不是图像中每个像素点的实际取样值，而是预测值与实际值之差。预测编码分为帧内预测和帧间预测，分别用来消除帧内冗余和帧间冗余。为了提高效率和效果，预测编码都是针对像素块完成，而不是像素点。帧内预测就是用邻近像素块预测该像素块，帧间预测则会先在邻近帧寻找该像素块的相似块，得到两者空间位置偏移量，再进行预测。我们把寻找偏移量（即相似块）的过程叫做运动估计，偏移量叫做运动矢量，我们把这种描述邻近帧差别的方式叫做运动补偿。

_注：这里所说的“预测”，实际上和“参考”是一个意思，就是找到被参考对象，与自己计算差异。_

**变换编码与量化**：绝大多数图像都有一个共同特征，平坦区域和内容缓慢变化区域占据一幅图像的大部分，而细节区域和内容突变区域则占小部分，即图像中直流和低频区占大部分，高频区占小部分。因此把图像从时空域变换到频域，更利于压缩。这个变换的过程，就叫变换编码，变换方法最常用的是离散余弦变换（Discrete Cosine Transform, DCT）。变换编码之后再把变换系数映射为较小的数值，这个过程叫做量化。

**熵编码**：利用信源的统计特性进行码率压缩的编码就称为熵编码，也叫统计编码。高频符号赋予短码，低频符号赋予长码，即可减少整体比特数。视频编码常用的熵编码有可变长编码（Variable Length Coding, VLC，也叫哈夫曼编码）和算术编码（Binary Arithmetic Coding, BAC）。

_运动估计、DCT、哈夫曼编码、算数编码的细节，这里就不展开了，感兴趣的朋友可以查阅相关资料。_

## H.264 码流结构

我们先了解 H.264 的码流结构，以及这样设计的原因，了解了码流结构后，编解码的过程就有了具体的依托。实际上 H.264 规范也是先规定了码流结构，再规定解码器的结构（_对于编码器的结构和实现模式没有具体的规定_），都是同样的道理。

编码器输出的码流中，数据的基本单位是句法元素，句法（Syntax）表征句法元素的组织结构，语义（Semantics）阐述句法元素的具体含义，所有的视频编码标准都是通过定义句法和语义来规范编码器工作流程的。

在 H.264 中，句法元素被组织成序列、图像、片、宏块、子块五个层次，如下图所示：

![](https://imgs.piasy.com/2017-09-21-h264_layers_simple.png)

分层有利于节省码流，例如下一层中的共用信息可以在上一层保存，而不是每个下层结构都携带一份。但在 H.264 的分层结构中，各层数据组织并没有形成强依赖关系，这样有助于提高鲁棒性。因为分组交换容易出错，如果存在强依赖关系，一旦头部丢失，那后面的数据就无法使用了。

相较于以往标准，H.264 取消了序列层和图像层（概念上存在，但实际上取消了），把原本属于序列和图像头部的大部分句法元素抽离出来，形成了序列参数集（Sequence Parameter Set, SPS）和图像参数集（Picture Parameter Set, PPS），其余的句法元素则放入片层。参数集是独立的数据单位，不依赖参数集外的其他句法元素，它们可以单独传输、重点保护。

更详细的分层结构如下图所示：

![](https://imgs.piasy.com/2017-09-21-h264_layers_detail.png)

最后，除了句法元素的分层，H.264 功能上也分为两层：视频编码层（Video Coding Layer, VCL）和网络抽象层（Network Abstraction Layer, NAL）。VCL 数据即编码处理的输出，正是它被分为了上述的五层结构。VCL 数据在传输或存储之前，会先封装进 NAL 单元，每个 NAL 单元则分为原始字节序列负荷（Raw Byte Sequence Payload, RBSP）和描述 RBSP（即 VCL 数据）的头部。

在分组交换网络传输中，NAL 单元各自独立、完整地放入一个分组，因此 NAL 单元之间无需分隔符，但在磁盘存储时，NAL 单元连续存放，必须引入起始码来分隔 NAL 单元。这个起始码就是连续的三字节数据 `0x000001`，如果数据需要对其，则在起始码之前添加若干字节的 0 来填充。

为防止编码数据和起始码冲突，定义如下“防止竞争”（emulation prevention，其实就是转义）规则（`00` 被解码器作为 NAL 单元结束，`01` 被解码器作为 NAL 单元开始，`03` 用于转义，`02` 尚未使用）：

![](https://imgs.piasy.com/2017-09-24-h264_nal_start_code.png)

编码器编码后如果检测到这些转义前序列，就在最后一个字节前插入 `0x03`，解码器解码时如果检测到 `0x000003`，就把最后的 `0x03` 丢弃。有了上面的转义规则后，解码器就可以把 `0x000001` 之后到 `0x000000` 之前的数据作为一个 NAL 数据单元了。

接下来就让我们简单过一下 H.264 的句法和语义。

### NAL 层

NAL 头的结构如下图所示：

![](https://imgs.piasy.com/2017-09-21-h264_nal_header.png)

H.264 的句法类似于 C 语言，有变量、操作、判断、循环等。

下图是 NAL 层的句法：

![](https://imgs.piasy.com/2017-09-21-h264_nal_syntax-1.png)

下面我们完整解析一下它的语义。

首先是 NAL 头：

+ `NumBytesInNALunit`：解码器在读取一个完整的 NAL 单元（`0x000001` 之后到 `0x000000` 之前的数据）后，计算出来的数据长度；
+ `forbidden_zero_bit`：读取 NAL 头部的最高比特位（Most Significant Bit, MSB），也就是网络字节序的首个比特位，通常都是 0，可以被用来表示这个数据单元是否损坏；
+ `nal_ref_idc`：读取 NAL 头部的接下来两个比特位，表示当前 NAL 单元的重要性，值越大越重要，0 表示本单元不会被其他单元参考，丢弃后影响最小，大于 0 的含义 H.264 规范并没有具体规定，通信双方可以灵活使用；
+ `nal_unit_type`：读取 NAL 头部的接下来五个比特位，表示当前 NAL 单元的类型，类型定义见下表：

![](https://imgs.piasy.com/2017-09-21-h264_nal_unit_types.png)

至此长度为一个字节的 NAL 头信息就解析完毕，接下来就是读取 RBSP 了，这个过程在一个循环中完成，读取 `NumBytesInNALunit` 个字节，并进行反转义处理（丢弃编码器插入的 `0x03`）：

+ 如果接下来还有三个字节，且它们是 `0x000003`，说明接下来三个字节是转义序列，那就读取接下来的两个字节存入 `rbsp_byte` 数组中，并增加 `NumBytesInRBSP` 计数器，`i += 2`，最后的 `emulation_prevention_three_byte` 为丢掉接下来的一个字节（`0x03`）；为什么明明处理了三个字节，`i` 只加了 2？因为循环体执行完毕之后 `i` 还会加 1；
+ 如果不是转义序列，那就直接读取接下来的一个字节存入 `rbsp_byte` 数组中，并增加 `NumBytesInRBSP` 计数器；

好了，到这里 NAL 数据单元就处理完毕，我们得到了 VCL 数据，且知道了它的类型。

这种句法描述的方式还是比较巧妙的，它以解码器伪代码的形式，来定义数据格式，真是一举两得。接下来 VCL 的各种句法和语义，本文就不展开了，只介绍我个人认为比较重要的字段。关于 H.264 句法和语义最权威的资料非 [H.264 SPEC](https://www.itu.int/rec/T-REC-H.264) 莫属。

### SPS

+ `profile_idc` 和 `level_idc`：指明所用的 profile 和 level，各 profile 的特性如下图所示：

![](https://imgs.piasy.com/2017-09-24-h264_profile.png)

+ `seq_parameter_set_id`：本 SPS 的 id；
+ `log2_max_frame_num_minus4`：记录 `frame_num` 句法元素的最大值，`frame_num` 表示所属图像解码顺序；
+ POC（Picture Order Count）相关：POC 表示图像播放顺序；
+ `num_ref_frames`：参考帧队列的最大长度，解码器据此开辟存储区，存放已解码的参考帧；
+ `gaps_in_frame_num_value_allowed_flag`，是否允许 `frame_num` 不连续，即是否允许编码器丢帧；
+ 图像宽高相关：`pic_width_in_mbs_minus1`，`pic_height_in_map_units_minus1`，`frame_mbs_only_flag`；
+ 图像编码模式相关：`frame_mbs_only_flag`，`mb_adaptive_frame_field_flag`，帧，场，帧场自适应；
+ 解码器图像裁剪相关：`frame_cropping...`

### PPS

+ `pic_parameter_set_id`：本 PPS 的 id；
+ `seq_parameter_seq_id`：本 PPS 引用的 SPS 的 id；
+ `entropy_coding_mode_flag`：熵编码模式，包括上下文自适应的可变长编码（Context Adaptive VLC, CAVLC）和上下文自适应的二进制算术编码（Context Adaptive BAC, CABAC）；
+ POC 相关参数；
+ 片组（Slice）相关参数；
+ `num_ref_idx_l0_active_minus1`，`num_ref_idx_l1_active_minus1`：目前参考帧队列的长度；
+ `pic_init_qp_minus26`：量化过程的精度由量化参数控制，这个句法元素设置量化参数初始值，量化参数会在 PPS、片、宏块这三个级别给出；

SPS 中的 `num_ref_frames` 表示参考帧队列的最大长度，解码器据此开辟存储区，存放已解码的参考帧，而 `num_ref_idx_l0_active_minus1` 和 `num_ref_idx_l1_active_minus1` 则表示目前实际已存在的参考帧队列长度。

参考帧队列长度是 H.264 中最重要的句法元素之一，因为编码器要通知解码器某个运动矢量所指向的是哪个参考图像时，并不是直接发送图像编号，而是该图像此时在参考帧队列中的序号。**因此维护参考帧队列是编解码器十分重要的工作。**

### 片、宏块、子块组织结构

从 `nal_unit_type` 可知，编码数据传输的基本单元都是片，片类型的 NAL 单元里，其数据组织如下图所示：

![](https://imgs.piasy.com/2017-09-24-h264_slice_structure.png)

### 片头

+ `first_mb_in_slice`：**片内首个宏块在图像中的位置**（_《新一代视频压缩编码标准:H.264/AVC(第2版)》书中说的是首个宏块地址，我是完全没有领会到这个含义的。另外，[StackOverflow 上面有人问如何对 H.264 码流按帧分隔，答案就是利用图像首片的 `first_mb_in_slice` 值为 0](https://stackoverflow.com/a/15071399/3077508)_）；
+ `slice_type`：片类型；

![](https://imgs.piasy.com/2017-09-22-h264_slice_type.png)

+ `pic_parameter_set_id`：本片引用的 PPS id；
+ `frame_num`：表示图像的解码顺序，同一幅图像的片 `frame_num` 相同，片句法中没有片顺序相关的句法，这个顺序保证由传输层实现；
+ `field_pic_flag`：图片编码模式，它和 SPS 中的两个句法元素共同决定图像编码模式；

![](https://imgs.piasy.com/2017-09-22-h264_pic_encode_mode.png)

+ POC 相关参数；
+ `slice_qp_delta`：指定当前片所有宏块的量化参数初始值；

### 宏块与子块相关句法

宏块与子块里面主要保存三部分信息：编码模式（宏块和子块的尺寸、分割信息）、预测信息、残差数据，具体如下表所示：

![](https://imgs.piasy.com/2017-09-24-h264_mb_syntax.png)

### 片组

片组是对片的一种组织方式，它定义了若干宏块构成片组的方式，映射方式和组织结构如下：

![](https://imgs.piasy.com/2017-09-24-h264_slice_group_table.png)

![](https://imgs.piasy.com/2017-09-24-h264_slice_group_details.png)

### 小结

到这里我们终于可以舒一口气了 :)

H.264 的句法是经过精心设计的，构成句法的各句法元素既相互依赖而又相互独立。依赖是为了减少冗余信息，提高编码效率，而独立是为了使通信更加鲁棒，在错误发生时限制错误的扩散。

## H.264 解码过程

在了解了 H.264 码流各层单元的组织结构和关系，也简单过了一下各句法元素之后，我们看看码流的解码过程。

**解码是以宏块为单位，依次进行熵解码、反量化、反变换，得到残差数据，再结合宏块里面的预测信息，找到被参考块，进而结合已解码被参考块和残差数据，得到本块的实际数据。宏块解码后，组合出片，片再组合出图像。**

解码器的各模块的结构如下图所示：

![](https://imgs.piasy.com/2017-09-19-h264_decoder_arch.png)

一帧图像的完整解码过程如下图所示：

![](https://imgs.piasy.com/2017-09-24-h264_decode_process.png)

NAL 单元的处理逻辑前面已经描述得很清楚了，最核心的过程是片解码的过程。其中的细节过程这里就不展开了，除了上面提到的熵解码、反量化、反变换、反预测外，**最值得一提的就是参考图像列表的维护了**，此外还有图像序列号的计算过程，具体可以仔细阅读《新一代视频压缩编码标准:H.264/AVC(第2版)》第七章的内容。

## H.264 编码过程

H.264 规范没有具体规定编码器的结构和实现模式，只要它产生出来的码流结构符合规范即可，这样编码过程就非常灵活了。不过其基本结构就是解码器的逆过程：**预测编码、变换编码、量化、熵编码**。

其基本结构如下图所示：

![](https://imgs.piasy.com/2017-09-24-h264_encoder_arch.png)

同样，每个环节的细节这里就不做展开，只提几个关键点：

+ 预测编码的过程，最重要的就是运动估计的搜索过程，同时这个过程也是最消耗计算资源的过程；
+ 帧内预测模式（宏块大小和分割方式等）的选择、运动补偿分割方式、运动矢量（MV）等，也是需要编码传输的；
+ 帧内预测跨片边界预测，每片必须独立编解码；
+ 运动搜索时，可以进行非整像素精度的运动估计，分数像素点并没有幅值，需要通过插值产生；
+ MV 的编码也需要较多的比特数，尤其是小的分割尺寸，所以 MV 也可以使用邻近已编码分割的 MV 预测而得；

**无论编码器的结构如何，相应的视频编码的控制都是编码器实现的核心问题**。基于 Lagrangian 优化算法的 H.264 编码控制模型如下图所示：

![](https://imgs.piasy.com/2017-09-24-h264_encoder_control_model-1.png)

编码过程中，并没有直接控制编码数据大小的方式，只能通过调整 QP 值间接控制，而由于 QP 和编码数据大小并没有确定的关系，所以**编码器的码率控制无法做到很精细，基本都靠试**。要么是中途改变后续宏块的质量，要么是重新编码改变所有宏块的质量。

编解码的过程还有一个比较独立的步骤是去方块滤波，这里也简单提一下。

方块效应原因：

+ 基于块的帧内、帧间预测残差的 DCT 变换，变换系数量化过程相对粗糙，反量化恢复的系数就有误差，造成图像块边界上的视觉不连续；
+ 运动补偿预测，在复制块的边界上产生数据不连续；

去方块滤波方案：

+ 环路滤波和后置滤波，环路滤波效果好，但复杂度相对较高；
+ 区分真实图像边界与方块边界，只有方块边界才需要滤波处理；

## H.264 视频编码传输

这里总结几点 H.264 就分组网络传输优化的特性：

+ 参数集：关键信息独立出来，可以重点保护；
+ 灵活宏块排序 FMO；
+ 冗余片 RS：对同一宏块使用不同编码参数（例如 QP）进行编码，每个冗余片都可以独立解码；
+ SP/SI 帧技术：实现流间切换（视频内容相同编码参数不同就用 SP 帧，视频内容相差很大就用 SI 帧）、拼接和随机接入、错误恢复；
+ NAL 头部未被 H.264 使用的空间，可以被网络传输层利用；

## H.264 的可伸缩编码

可伸缩编码（Scalable Video Coding, SVC）实质上是将视频信息按照重要性分解，对分解的各个部分按照其自身的统计特性进行编码。一般它会将视频编码为一个基本层和一组增强层。基本层包含基本信息，可以独立解码，增强层依赖于基本层，可以对基本层的信息进行增强，增强层越多，视频信息的恢复质量也就越高。

SVC 通常有三种：

+ 空域可伸缩：可以解码出多种分辨率的视频；
+ 时域可伸缩：可以解码出多种帧率的视频，分辨率相同；
+ 质量可伸缩：可以解码出多种码率的视频，分辨率、帧率相同；

SVC 的实现细节这里不做展开，感兴趣的朋友可以查阅相关资料。

## 总结

本文中我尝试解答 H.264 编解码最核心的两个问题：H.264 编解码的过程是怎样的？H.264 码流的结构是怎样的？

在编解码基础部分中，我对核心过程做了通俗化地解读，但涉及到的具体算法没有展开，在码流结构部分花了较长的篇幅，大致把各层单元的组织结构搞清楚了，结合简单的编解码过程概述，应该可以对编解码过程有比较清晰的宏观认识。

限于篇幅，本文无法把涉及到的概念都描述清楚，没有相关基础的读者需要查阅专业资料，而有相关基础的读者其实未必需要这样一篇总结文章，因此本文对于我梳理自己的思路意义更大，敬请谅解。

最后，在 AI 浪潮下，视频编解码肯定也能和 AI 结合，在视频编解码的过程中，我认为至少以下几点 AI 可以发挥很大的作用：

+ 运动估计过程中，搜索策略的选择，应该是 AI 能否发挥作用的环节；
+ 自适应分块，AI 可以对图像预处理，分析出图像细节分布；
+ 编码控制：基于场景、内容，选择编码策略，AI 也可发挥很大价值；
